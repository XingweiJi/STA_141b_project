{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sqla\n",
    "import random\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct connection to database\n",
    "conn = sqla.create_engine('sqlite:///yelp.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query data from database\n",
    "test = pd.read_sql_query(\"select * from review limit 20\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Terrible. Dry corn bread. Rib tips were all fat and mushy and had no flavor. If you want bbq in this neighborhood go to john mulls roadkill grill. Trust me.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.5333333333333333, subjectivity=0.8)\n",
      "CPU times: user 1.4 ms, sys: 1.02 ms, total: 2.42 ms\n",
      "Wall time: 3.86 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Default estimator\n",
    "m = test['text'][2]\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "senti = TextBlob(m)\n",
    "print(senti.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.9136346853028313, p_neg=0.08636531469717702)\n",
      "CPU times: user 4.15 s, sys: 514 ms, total: 4.66 s\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NaiveBayes estimator:\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "senti = TextBlob(m,analyzer=NaiveBayesAnalyzer())\n",
    "print(senti.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**textblob doesn't have a acceptable accuracy especially for food review. Naivebayes is slow and inaccurate. I did a little research on how textblob calculates the sentiment. It turns out they have a XML file that contains polarity score for each words, and the overall polarity score is just the average of polarity scores of each word (Link: https://planspace.org/20150607-textblob_sentiment/ ). This is a poor way of estimating the sentiment score. Consider training my own NLP model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy Text Categorizer    \n",
    "I will train the model with Amazon's food review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_review = pd.read_csv('Amazon_Reviews.csv')\n",
    "amz_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale score between -1 and 1\n",
    "norm_score = np.interp(amz_review.Score.values,(amz_review.Score.values.min(),amz_review.Score.values.max()),(-1,+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_review['norm_score'] = norm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.',\n",
       " 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_review['train_tuple'] = amz_review.apply(lambda row: (row['Text'],row['Score']),axis=1)\n",
    "train = amz_review['train_tuple'].tolist()\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions from spacy documentation\n",
    "def load_data(limit=0, split=0.8):\n",
    "    train_data = train\n",
    "    np.random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{'POSITIVE': y >= 3} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(\"Number of texts to train from\",\"t\" , int)\n",
    "n_texts=300000\n",
    "#You can increase texts count if you have more computational power.\n",
    "#(\"Number of training iterations\", \"n\", int))\n",
    "n_iter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')  # create english Language class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading food reviews data...\n",
      "Using 30000 examples (24000 training, 6000 evaluation)\n"
     ]
    }
   ],
   "source": [
    "# add the text classifier to the pipeline if it doesn't exist\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'textcat' not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "\n",
    "# add label to text classifier\n",
    "textcat.add_label('POSITIVE')\n",
    "\n",
    "# load the dataset\n",
    "print(\"Loading food reviews data...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "      .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "train_data = list(zip(train_texts,\n",
    "                      [{'cats': cats} for cats in train_cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "204.768\t0.910\t0.983\t0.945\n",
      "time for one iteration is 155.03080892562866\n",
      "123.836\t0.925\t0.975\t0.949\n",
      "time for one iteration is 178.083074092865\n",
      "94.492\t0.930\t0.973\t0.951\n",
      "time for one iteration is 176.36578583717346\n",
      "84.068\t0.934\t0.969\t0.951\n",
      "time for one iteration is 181.42677283287048\n",
      "74.010\t0.934\t0.969\t0.951\n",
      "time for one iteration is 185.3597228527069\n",
      "68.926\t0.933\t0.969\t0.950\n",
      "time for one iteration is 188.23954820632935\n",
      "64.172\t0.935\t0.966\t0.950\n",
      "time for one iteration is 177.8659210205078\n",
      "60.054\t0.935\t0.968\t0.951\n",
      "time for one iteration is 180.7558081150055\n",
      "63.498\t0.935\t0.968\t0.951\n",
      "time for one iteration is 178.3223419189453\n",
      "57.024\t0.936\t0.968\t0.951\n",
      "time for one iteration is 174.05425381660461\n",
      "CPU times: user 48min 14s, sys: 1min 54s, total: 50min 9s\n",
      "Wall time: 29min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "    for i in range(n_iter):\n",
    "        start = time.time()\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                       losses=losses)\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            # evaluate on the dev data split off in load_data()\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        stop = time.time()\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f']))\n",
    "        print('time for one iteration is {}'.format(stop-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': 0.0005693367565982044}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(test['text'][2])\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': 0.9758155345916748}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text2 = 'This tea is fun to watch as the flower expands in the water. Very smooth taste and can be used again and again in the same day. If you love tea, you gotta try these \"flowering teas\"'\n",
    "doc2 = nlp(test_text2)\n",
    "doc2.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The trained model doesn't perform well as well. Have to train on more datasets and see the result. Now, try google NLP api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/Users/jixingwei/Desktop/STA_141b_project/yelp_review.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try Google NLP API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello, world!\n",
      "Sentiment: 0.30000001192092896, 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "# The text to analyze\n",
    "text = u'Hello, world!'\n",
    "document = types.Document(\n",
    "    content=text,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# Detects the sentiment of the text\n",
    "sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "\n",
    "print('Text: {}'.format(text))\n",
    "print('Sentiment: {}, {}'.format(sentiment.score, sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "def AnalyseSentiment(text):\n",
    "    document = types.Document(content=text,type=enums.Document.Type.PLAIN_TEXT)\n",
    "    # Detects the sentiment of the text\n",
    "    sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "    return (sentiment.score, sentiment.magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 3500 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>x7mDIiDB3jEiPGPHOmDzyw</td>\n",
       "      <td>2</td>\n",
       "      <td>The pizza was okay. Not the best I've had. I p...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-13 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>dDl8zu1vWPdKGihJrwQbpw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23 00:00:00.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>LZp4UX5zK3e-c5ZGSeo3kA</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elqbBhBfElMNSrjFqW3now</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Er4NBWCmCD4nM8_p1GRdow</td>\n",
       "      <td>2</td>\n",
       "      <td>Back in 2005-2007 this place was my FAVORITE t...</td>\n",
       "      <td>2</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-05 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>jsDu6QEJHbwP2Blom1PLCA</td>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                        date  funny  \\\n",
       "0  iCQpiavjjPzJ5_3gPD5Ebg     0  2011-02-25 00:00:00.000000      0   \n",
       "1  pomGBqfbxcqPv14c3XH-ZQ     0  2012-11-13 00:00:00.000000      0   \n",
       "2  jtQARsP6P-LbkyjbO1qNGg     1  2014-10-23 00:00:00.000000      1   \n",
       "3  elqbBhBfElMNSrjFqW3now     0  2011-02-25 00:00:00.000000      0   \n",
       "4  Ums3gaP2qM3W1XcA5r6SsQ     0  2014-09-05 00:00:00.000000      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  x7mDIiDB3jEiPGPHOmDzyw      2   \n",
       "1  dDl8zu1vWPdKGihJrwQbpw      5   \n",
       "2  LZp4UX5zK3e-c5ZGSeo3kA      1   \n",
       "3  Er4NBWCmCD4nM8_p1GRdow      2   \n",
       "4  jsDu6QEJHbwP2Blom1PLCA      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  The pizza was okay. Not the best I've had. I p...       0   \n",
       "1  I love this place! My fiance And I go here atl...       0   \n",
       "2  Terrible. Dry corn bread. Rib tips were all fa...       3   \n",
       "3  Back in 2005-2007 this place was my FAVORITE t...       2   \n",
       "4  Delicious healthy food. The steak is amazing. ...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "1  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "2  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "3  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "4  msQe1u7Z_XuqjGoqhB0J5g  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"select * from review limit 3500\",conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.10000000149011612, 3.200000047683716)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnalyseSentiment(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -2\n",
       "1      -5\n",
       "2      -1\n",
       "3      -2\n",
       "4      -5\n",
       "5      -1\n",
       "6      -5\n",
       "7      -5\n",
       "8      -4\n",
       "9      -2\n",
       "10     -5\n",
       "11     -1\n",
       "12     -5\n",
       "13     -4\n",
       "14     -5\n",
       "15     -4\n",
       "16     -5\n",
       "17     -5\n",
       "18     -5\n",
       "19     -5\n",
       "20     -5\n",
       "21     -2\n",
       "22     -5\n",
       "23     -1\n",
       "24     -5\n",
       "25     -1\n",
       "26     -1\n",
       "27     -5\n",
       "28     -5\n",
       "29     -4\n",
       "       ..\n",
       "3470   -5\n",
       "3471   -2\n",
       "3472   -5\n",
       "3473   -5\n",
       "3474   -3\n",
       "3475   -5\n",
       "3476   -1\n",
       "3477   -5\n",
       "3478   -5\n",
       "3479   -4\n",
       "3480   -4\n",
       "3481   -5\n",
       "3482   -2\n",
       "3483   -4\n",
       "3484   -5\n",
       "3485   -5\n",
       "3486   -2\n",
       "3487   -5\n",
       "3488   -3\n",
       "3489   -2\n",
       "3490   -3\n",
       "3491   -2\n",
       "3492   -4\n",
       "3493   -5\n",
       "3494   -5\n",
       "3495   -4\n",
       "3496   -3\n",
       "3497   -5\n",
       "3498   -3\n",
       "3499   -5\n",
       "Name: test_score, Length: 3500, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_score'] = df['stars'].apply(lambda star: -star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['text'].apply(lambda text: AnalyseSentiment(text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>test_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>x7mDIiDB3jEiPGPHOmDzyw</td>\n",
       "      <td>2</td>\n",
       "      <td>The pizza was okay. Not the best I've had. I p...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-13 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>dDl8zu1vWPdKGihJrwQbpw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23 00:00:00.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>LZp4UX5zK3e-c5ZGSeo3kA</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elqbBhBfElMNSrjFqW3now</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Er4NBWCmCD4nM8_p1GRdow</td>\n",
       "      <td>2</td>\n",
       "      <td>Back in 2005-2007 this place was my FAVORITE t...</td>\n",
       "      <td>2</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-05 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>jsDu6QEJHbwP2Blom1PLCA</td>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                        date  funny  \\\n",
       "0  iCQpiavjjPzJ5_3gPD5Ebg     0  2011-02-25 00:00:00.000000      0   \n",
       "1  pomGBqfbxcqPv14c3XH-ZQ     0  2012-11-13 00:00:00.000000      0   \n",
       "2  jtQARsP6P-LbkyjbO1qNGg     1  2014-10-23 00:00:00.000000      1   \n",
       "3  elqbBhBfElMNSrjFqW3now     0  2011-02-25 00:00:00.000000      0   \n",
       "4  Ums3gaP2qM3W1XcA5r6SsQ     0  2014-09-05 00:00:00.000000      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  x7mDIiDB3jEiPGPHOmDzyw      2   \n",
       "1  dDl8zu1vWPdKGihJrwQbpw      5   \n",
       "2  LZp4UX5zK3e-c5ZGSeo3kA      1   \n",
       "3  Er4NBWCmCD4nM8_p1GRdow      2   \n",
       "4  jsDu6QEJHbwP2Blom1PLCA      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  The pizza was okay. Not the best I've had. I p...       0   \n",
       "1  I love this place! My fiance And I go here atl...       0   \n",
       "2  Terrible. Dry corn bread. Rib tips were all fa...       3   \n",
       "3  Back in 2005-2007 this place was my FAVORITE t...       2   \n",
       "4  Delicious healthy food. The steak is amazing. ...       0   \n",
       "\n",
       "                  user_id  test_score  score  \n",
       "0  msQe1u7Z_XuqjGoqhB0J5g          -2   -0.1  \n",
       "1  msQe1u7Z_XuqjGoqhB0J5g          -5    0.7  \n",
       "2  msQe1u7Z_XuqjGoqhB0J5g          -1   -0.3  \n",
       "3  msQe1u7Z_XuqjGoqhB0J5g          -2   -0.2  \n",
       "4  msQe1u7Z_XuqjGoqhB0J5g          -5    0.7  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['test_score'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>x7mDIiDB3jEiPGPHOmDzyw</td>\n",
       "      <td>2</td>\n",
       "      <td>The pizza was okay. Not the best I've had. I p...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-13 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>dDl8zu1vWPdKGihJrwQbpw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23 00:00:00.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>LZp4UX5zK3e-c5ZGSeo3kA</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elqbBhBfElMNSrjFqW3now</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Er4NBWCmCD4nM8_p1GRdow</td>\n",
       "      <td>2</td>\n",
       "      <td>Back in 2005-2007 this place was my FAVORITE t...</td>\n",
       "      <td>2</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-05 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>jsDu6QEJHbwP2Blom1PLCA</td>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                        date  funny  \\\n",
       "0  iCQpiavjjPzJ5_3gPD5Ebg     0  2011-02-25 00:00:00.000000      0   \n",
       "1  pomGBqfbxcqPv14c3XH-ZQ     0  2012-11-13 00:00:00.000000      0   \n",
       "2  jtQARsP6P-LbkyjbO1qNGg     1  2014-10-23 00:00:00.000000      1   \n",
       "3  elqbBhBfElMNSrjFqW3now     0  2011-02-25 00:00:00.000000      0   \n",
       "4  Ums3gaP2qM3W1XcA5r6SsQ     0  2014-09-05 00:00:00.000000      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  x7mDIiDB3jEiPGPHOmDzyw      2   \n",
       "1  dDl8zu1vWPdKGihJrwQbpw      5   \n",
       "2  LZp4UX5zK3e-c5ZGSeo3kA      1   \n",
       "3  Er4NBWCmCD4nM8_p1GRdow      2   \n",
       "4  jsDu6QEJHbwP2Blom1PLCA      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  The pizza was okay. Not the best I've had. I p...       0   \n",
       "1  I love this place! My fiance And I go here atl...       0   \n",
       "2  Terrible. Dry corn bread. Rib tips were all fa...       3   \n",
       "3  Back in 2005-2007 this place was my FAVORITE t...       2   \n",
       "4  Delicious healthy food. The steak is amazing. ...       0   \n",
       "\n",
       "                  user_id  score  \n",
       "0  msQe1u7Z_XuqjGoqhB0J5g   -0.1  \n",
       "1  msQe1u7Z_XuqjGoqhB0J5g    0.7  \n",
       "2  msQe1u7Z_XuqjGoqhB0J5g   -0.3  \n",
       "3  msQe1u7Z_XuqjGoqhB0J5g   -0.2  \n",
       "4  msQe1u7Z_XuqjGoqhB0J5g    0.7  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('review_with_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
